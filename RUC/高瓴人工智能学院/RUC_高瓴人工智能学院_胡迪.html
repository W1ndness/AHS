<!DOCTYPE HTML>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>胡迪-教师系统</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content=""/>
    <meta name="keywords" content=""/>
    <meta name="author" content=""/>

    <link href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,700" rel="stylesheet">

    <!-- Animate.css -->
    <link rel="stylesheet" href="/assets/css/animate.css">

    <!-- Bootstrap  -->
    <link rel="stylesheet" href="/assets/css/bootstrap.css">
  <link href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <!-- Theme style  -->
    <link rel="stylesheet" href="/assets/addons/teacher/css/young.css">
    <!-- Modernizr JS -->
    <script src="/assets/js/modernizr-2.6.2.min.js"></script>
    <!-- FOR IE9 below -->
    <!--[if lt IE 9]>
    <script src="/assets/js/respond.min.js"></script>
    <![endif]-->

    <link href="/assets/css/util.min.css?v=1.1" rel="stylesheet">
	<link href="/assets/libs/video/video-js.min.css?v=1.1" rel="stylesheet">

</head>
<body>
<nav id="mainNav" class="navbar navbar-default navbar-fixed-top p-b-10">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                    data-target="#navbar-collapse-menu">
                <span class="sr-only">Toggle navigation</span><i class="fa fa-bars"></i>
            </button>
            <a class="navbar-brand page-scroll" href="http://ai.ruc.edu.cn"><img
                    src="/assets/img/cn_ruc_logo.png" height="40"></a>
        </div>

        <div class="collapse navbar-collapse" id="navbar-collapse-menu">
            <ul class="nav navbar-nav navbar-right m-t-10">
                <li><a href="http://ai.ruc.edu.cn">首页</a></li>
                <li><a href="/index/teacher.teacher/info.html">教师中心</a></li>
                <li><a href="/addons/teacher/index/info.html?user_id=13&ruccode=20200218&ln=en">EN</a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
</nav>

<div id="colorlib-page" >
    <div class="container-wrap">
        <a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle hide" data-toggle="collapse" data-target="#navbar"
           aria-expanded="false" aria-controls="navbar"><i></i></a>
        <aside id="colorlib-aside" role="complementary" class="border js-fullheight">
            <div class="text-center">
                <div class="author-img" style="background-image: url(/uploads/20211203/32f9133f30273e801fb5f054ab3228c5.png);"></div>
                <h1>胡迪</h1>
                <span class="position"></span> <span
                    class="position">准聘助理教授</span>
            </div>

            <div class="text-desc fs-16 lh-17 p-all-15 ">
                胡迪，分别于2014年和2019年获得西北工业大学学士和博士学位。曾任百度研究院人工智能研究员，于2020年9月加入中国人民大学，任助理教授。其主要研究方向为机器多模态感知与学习，以主要作者身份在领域顶级国际会议及期刊上发表论文20余篇，如 TPAMI、NeurIPS、CVPR、ICCV、ECCV、AAAI等。攻博期间曾入选 CVPR Doctoral Consortium（大陆共4人）；荣获2019 ACM XI’AN 优博奖，2020中国人工智能学会优博奖，2021年陕西省优博奖；入选中国科协青年人才托举工程，中国人民大学“杰出学者”计划，百度全球顶尖人工智能人才计划。受邀为CVPR、ICCV、ECCV、NeurIPS等多个国际高水平会议及期刊审稿。部分研究成果正同产业应用相结合以发挥其社会价值，如利用机器辅助手段提升视障人士的感知能力等。            </div>
			            <div class=" p-all-15 m-t-20 text-center fs-14">
                <span class="fs-14 "><a href="https://gewu-lab.github.io/"  class="btn btn-info"  target="_blank">点击访问个人主页</a></span>
                <p class="text-web"></p>
            </div>
			
        </aside>

        <div id="colorlib-main">
		             <section class="colorlib-about " data-section="education">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">视频简介</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12">
                            <div>
							<video id="example_video_1"  poster="/uploads/20210525/8ff68692efbd615eea2f86c5fc102e54.jpg" class="video-js vjs-default-skin vjs-big-play-centered vjs-16-9" controls controls preload="auto" poster="" data-setup="{}">
    <source src="/uploads/20210525/b87ab93a3deb00ebb5b16b16ab229524.mp4" type="video/mp4">
  </video>
							</div>
                        </div>
                    </div>
                </div>
            </section>
            
            <!--education-->
                        <section class="colorlib-about " data-section="education">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">教育经历</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 ">
                          
							<ul style="margin:0;
 padding-left:20px;">
                                                                        <li style="list-style-type: disc;" class="lh-20">2010-2019年 西北工业大学 本科-博士<br/></li>
                                                                    </ul>
                        </div>
                    </div>
                </div>
            </section>
            
            <!--work-->
                        <section class="colorlib-about " data-section="work">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">工作经历</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
                          
							<ul style="margin:0;
 padding-left:20px;">
                                                                        <li style="list-style-type: disc;" class="lh-20">2020年至今，中国人民大学高瓴人工智能学院，准聘助理教授<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">2019-2020年，百度研究院，人工智能研究员<br/></li>
                                                                    </ul>
                        </div>
                    </div>
                </div>
            </section>
            
            <!--Research-->
                        <section class="colorlib-about " data-section="work">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">研究方向</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
                            <div class="lh-20">机器多模态感知与学习：以大脑的多通道知觉为背景，挖掘并探究多模态信息（如图像、声音、触觉等）在机器感知、推理与理解等方向的潜在问题与方法，让机器具备『多感官认知能力』。部分研究介绍请观看B站视频（https://www.bilibili.com/video/BV1DK4y1P7Ep?p=2）。<br />
<br />
GeWu-Lab实验室网站: https://gewu-lab.github.io/</div>
                        </div>
                    </div>
                </div>
            </section>
            
            <!--student-->
                        <section class="colorlib-about " data-section="student">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">学生要求</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
                            <div class="lh-20">对客观存在保持好奇心，自驱，刻苦，以做有趣、有温度、有价值的研究为目标。<br />
更多关于实验室介绍，请参见知乎文章：https://zhuanlan.zhihu.com/p/496452639<br />
<br />
2021级直博生卫雅珂，指导发表多篇CCF-A类论文（如T-PAMI, CVPR Oral文章）<br />
2020级博士生与硕士生，发表多篇CCF-A类会议Oral文章<br />
2017级上交本科生钱锐，指导发表多篇CCF-A类论文，现于CUHK MMLab攻读博士学位<br />
访问学生邓安东（上交），指导发表/在投多篇CCF-A类论文，现赴UCF攻读博士学位</div>
                        </div>
                    </div>
                </div>
            </section>
                        <!--course-->
                        <section class="colorlib-about " data-section="course">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">教授课程</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
                           
							 <ul style="margin:0;
 padding-left:20px;">
                                                                        <li style="list-style-type: disc;" class="lh-20">本科生课程：《人工智能与Python程序设计》，2021-2022<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">研究生课程：《模式识别与计算机视觉》，2021-2022<br/></li>
                                                                    </ul>
                        </div>
                    </div>
                </div>
            </section>
            
            <!--project-->
                        <section class="colorlib-about " data-section="education">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">科研项目</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
                           
							 <ul style="margin:0;
 padding-left:20px;">
                                                                        <li style="list-style-type: disc;" class="lh-20">中国科协青年人才托举工程项目（2022-2024），主持<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">国家自然科学基金青年科学基金项目（2022-2024）：自然场景下机器的视听感知与学习，主持<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">百度研究院（2021-2022）：跨模态迁移学习场景下的可解释性研究，主持<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">腾讯AI Lab犀牛鸟专项研究计划（2021-2022）：动态视音场景下多说话人跟踪与日志方法研究，主持<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">中国人民大学新教师启动金项目（2021-2022）：面向视听信息的多模态认知计算，主持<br/></li>
                                                                    </ul>
                        </div>
                    </div>
                </div>
            </section>
                        <section class="colorlib-contact" data-section="filelist">
                <div class="colorlib-narrow-content">
                    <div class="row">
					                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 ">
                            <h2 class="colorlib-heading">学术论文</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
		
                                                        <div class="m-b-15"><span class="fs-24 "><strong>2022</strong></span>
                            </div>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Self-supervised Learning for Heterogeneous Audiovisual Scene Analysis</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Zheng Wang, Feiping Nie, Rong Wang, Xuelong Li</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  TMM</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Guangyao Li*, Yake Wei*, Yapeng Tian*, Chenliang Xu, Ji-Rong Wen, Di Hu</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  CVPR (ORAL)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Balanced Multimodal Learning via On-the-fly Gradient Modulation</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Xiaokang Peng*, Yake Wei*, Andong Deng, Dong Wang, Di Hu</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  CVPR (ORAL)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>SepFusion: Finding Optimal Fusion Structures for Visual Sound Separation</strong></span>	
									
									<!--
									 
									
									(<a
                                        href="[]"><i class="fa fa-download"></i>下载</a>
										)
										-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Dongzhan Zhou, Xinchi Zhou, Di Hu*, Hang Zhou, Lei Bai, Ziwei Liu, Wanli Ouyang</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  AAAI</div>
							
								                        <div style="margin-top: 10px"><span><i class="fa fa-link m-r-10"></i> 下载： </span>
                                                    </div>
                        						
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Visual Sound Localization in-the-Wild by Cross-Modal Interference Erasing</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Xian Liu, Rui Qian, Hang Zhou, Di Hu, Weiyao Lin, Ziwei Liu, Bolei Zhou, Xiaowei Zhou</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  AAAI</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                                                        <div class="m-b-15"><span class="fs-24 "><strong>2021</strong></span>
                            </div>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Class-aware Sounding Objects Localization via Audiovisual Correspondence</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Yake Wei, Rui Qian, Weiyao Lin, Ruihua Song, Ji-Rong Wen</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  TPAMI</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Yapeng Tian, Di Hu*, Chenliang Xu*</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  CVPR</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Unsupervised Multi-Source Domain Adaptation for Person Re-Identification</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Zechen Bai, Zhigang Wang, Jian Wang, Di Hu*, Errui Ding*</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  CVPR</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Temporal Relational Modeling with Self-Supervision for Action Segmentation</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Dong Wang, Di Hu*, Xingjian Li, Dejing Dou</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  AAAI</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                                                        <div class="m-b-15"><span class="fs-24 "><strong>2020</strong></span>
                            </div>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Rui Qian, Minyue Jiang, Xiao Tan, Shilei Wen, Errui Ding, Weiyao Lin, Dejing Dou</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  NeurIPS</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i> A Two-Stage Framework for Multiple Sound-Source Localization</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Rui Qian, Di Hu, Heinrich Dinkel, Mengyue Wu, Ning Xu, Weiyao Lin</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>   In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW), 2020.</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Co-Learn Sounding Object Visual Grounding and Visually Indicated Sound Separation in A Cycle</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Yapeng Tian, Di Hu, Chenliang Xu</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW), 2020.</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i> Does Ambient Sound Help? - Audiovisual Crowd Counting</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, LichaoMou, Qingzhong Wang, Junyu Gao, Yuansheng Hua, Dejing Dou, and Xiaoxiang Zhu</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW), 2020.</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Heterogeneous Scene Analysis via Self-supervised Audiovisual Learning</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Zheng Wang, HaoyiXiong, Dong Wang, FeipingNie, and Dejing Dou</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW), 2020.</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Multiple Sound Sources Localization from Coarse to Fine</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Rui Qian, Di Hu, Heinrich Dinkel, Mengyue Wu, Ning Xu, and Weiyao Lin</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the European Conference on Computer Vision (ECCV), 2020.</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Cross-Task Transfer for Multimodal Aerial Scene Recognition</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Xuhong Li, LichaoMou, Pu Jin, Dong Chen, Liping Jing, Xiaoxiang Zhu, and Dejing Dou</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the European Conference on Computer Vision (ECCV), 2020.</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                                                        <div class="m-b-15"><span class="fs-24 "><strong>2019</strong></span>
                            </div>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Dense Multimodal Fusion for Hierarchically Joint Representation</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Chengze Wang, FeipingNie, and Xuelong Li</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019.</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Listen to the Image</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Dong Wang, FeipingNie, Qi Wang, and Xuelong Li</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Deep Multimodal Clustering for Unsupervised Audiovisual Learning</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, FeipingNie, and Xuelong Li</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Deep Linear Discriminant Analysis Hashing</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, FeipingNie, and Xuelong Li</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>   Sci Sin Inform, 2019. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                                                        <div class="m-b-15"><span class="fs-24 "><strong>2018</strong></span>
                            </div>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Deep Binary Reconstruction for Cross-modal Hashing</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, FeipingNie, and Xuelong Li</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  IEEE Trans. Multimedia (TMM), 2018.</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Discrete Spectral Hashing for Efficient Similarity Retrieval</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, FeipingNie, and Xuelong Li</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  IEEE Trans. Image Processing (TIP), 2018. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                                                        <div class="m-b-15"><span class="fs-24 "><strong>2017</strong></span>
                            </div>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Large Graph Hashing with Spectral Rotation</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Xuelong Li, Di Hu, and FeipingNie</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the AAAIConferenceonArtificialIntelligence (AAAI), 2017. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Deep Binary Reconstruction for Cross-modal Hashing</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Xuelong Li, Di Hu, and FeipingNie</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the ACM Conference on Multimedia (ACMMM), 2017. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i> Image2song: Song Retrieval via Bridging Image Content and Lyric Words</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Xuelong Li, Di Hu, and Xiaoqiang Lu</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the IEEE Conference on Computer Vision (ICCV), 2017. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                                                        <div class="m-b-15"><span class="fs-24 "><strong>2016</strong></span>
                            </div>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Temporal Multimodal Learning in Audiovisual Speech Recognition</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Xuelong Li, and Xiaoqiang Lu</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                            							
							<div class="media m-l-30">
								<div class="media-left media-top">
								<i class="fa fa-caret-right fa-sm"></i>
								</div>
								
							
								<div class="media-body">
								 <div class="m-b-10"><span class="fs-18 "><strong><i
                                    cass="fa fa-caret-right"></i>Multimodal Learning via Exploring Deep Semantic Similarity</strong></span>	
									
									<!--
									-->
                            </div>
                            <div class="fs-14 lh-15"><i class="fa fa-user"></i> Di Hu, Xiaoqiang Lu, and Xuelong Li</div>
							<div class="fs-14 lh-15"><i class="fa fa-bank"></i>  In Proceedings of the ACM Conference on Multimedia (ACMMM), 2016. (CCF A)</div>
							
														
                           
								</div>
							</div>

                           
                            <hr>
                                                    </div>
                    </div>
                </div>
            </section>
			
            <!--honor-->
                        <section class="colorlib-about " data-section="education">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">荣誉奖励</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
                            
							 <ul style="margin:0;
 padding-left:20px;">
                                                                        <li style="list-style-type: disc;" class="lh-20">2021.12 中国科协青年人才托举工程项目<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">2021.10 荣获陕西省优秀博士论文奖<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">2020.9 荣获中国人工智能学会优秀博士论文奖<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">2019.8 入选百度『AIDU』全球顶尖人工智能人才计划<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">2019.8 荣获ACM XI’AN优秀博士论文奖（共2人）<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">2019.5 入选CVPR Doctoral Consortium博士生论坛（大陆共4人）<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">2018.7 荣获国家留学基金委赴卡内基梅隆大学联合培养学金<br/></li>
                                                                    </ul>
                        </div>
                    </div>
                </div>
            </section>
            
            <!--job-->
                        <section class="colorlib-about " data-section="education">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading ">社会兼职</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
                           
							 <ul style="margin:0;
 padding-left:20px;">
                                                                        <li style="list-style-type: disc;" class="lh-20">期刊审稿人: TPAMI, TNNLS, TIP, TKDE, TCSVT, TMM, etc.<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">会议程序委员: NeurIPS 2020-2021, CVPR 2018 2020-2022, ICCV 2019 2021, ECCV2020,  ICML 2021, AAAI 2018 2020-2022, ICLR 2021<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">联合组织者: <br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">CVPR 2021 Tutorial on Audio-visual Scene Understanding<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">WACV 2021 Tutorial on Audio-visual Scene Understanding<br/></li>
                                                                        <li style="list-style-type: disc;" class="lh-20">ICDM 2019 Tutorial on Automated Deep Learning: Theory, Algorithms, Platforms, and Applications<br/></li>
                                                                    </ul>
                        </div>
                    </div>
                </div>
            </section>
            
            <section class="colorlib-contact" data-section="contact">
                <div class="colorlib-narrow-content">
                    <div class="row">
                        <div class="col-md-6 col-md-offset-3 col-md-pull-3 "
                             >
                            <h2 class="colorlib-heading">联系</h2>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-12 " >
                            <p>电话：--</p>
                            <p>邮箱：dihu[at]ruc.edu.cn</p>
                            <p>个人网页：https://gewu-lab.github.io/</p>
                            <p>办公地址：北京市海淀区中关村大街59号文化大厦2102</p>

                        </div>
                    </div>
                </div>
            </section>
        </div><!-- end:colorlib-main -->
    </div>
</div>



<!-- jQuery -->
<script src="/assets/js/jquery-3.5.1.js"></script>
<!-- jQuery Easing -->
<script src="/assets/js/jquery.easing.1.3.js"></script>
<!-- Bootstrap -->
<script src="/assets/js/bootstrap.min.js"></script>
<!-- Waypoints -->
<script src="/assets/js/jquery.waypoints.min.js"></script>
<!-- swiper -->

<!-- Waypoints -->
<script src="/assets/js/modernizr-2.6.2.min.js"></script>
<!-- MAIN JS -->
<script src="/assets/addons/teacher/js/young.js"></script>

<script src="/assets/libs/video/video.min.js"></script>

<script>
var box=$(".text-desc");
box.style.letterSpacing = '-.1em';
box.innerHTML = box.innerHTML.replace(/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g, '').split("").join(" ").replace(/\s{3}/g, " &nbsp; ");
</script>

</body>
</html>

